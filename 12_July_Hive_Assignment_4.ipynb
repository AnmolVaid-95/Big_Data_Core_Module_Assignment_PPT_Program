{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1.  Write a Python program that uses the HiveQL language to create a table named \"Employees\" with columns for \"id,\" \"name,\" and \"salary.\"**"
      ],
      "metadata": {
        "id": "WvRshIMYYrfB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLwaO9XrYkeq"
      },
      "outputs": [],
      "source": [
        "from pyhive import hive\n",
        "\n",
        "def create_employees_table():\n",
        "    # Connect to Hive server\n",
        "    connection = hive.connect('localhost')\n",
        "\n",
        "    # Create a cursor\n",
        "    cursor = connection.cursor()\n",
        "\n",
        "    # Execute the HiveQL query to create the Employees table\n",
        "    create_table_query = '''\n",
        "    CREATE TABLE Employees (\n",
        "        id INT,\n",
        "        name STRING,\n",
        "        salary FLOAT\n",
        "    )\n",
        "    '''\n",
        "    cursor.execute(create_table_query)\n",
        "\n",
        "    # Commit the changes and close the connection\n",
        "    connection.commit()\n",
        "    connection.close()\n",
        "\n",
        "    print(\"Employees table created successfully!\")\n",
        "\n",
        "# Call the function to create the Employees table\n",
        "create_employees_table()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.  Create a Python program that retrieves records from a Hive table named \"Customers\" where the age is greater than 30.**"
      ],
      "metadata": {
        "id": "sFAXT6XJY5hy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyhive import hive\n",
        "\n",
        "def retrieve_customers_with_age_greater_than_30():\n",
        "    # Connect to Hive server\n",
        "    connection = hive.connect('localhost')\n",
        "\n",
        "    # Create a cursor\n",
        "    cursor = connection.cursor()\n",
        "\n",
        "    # Execute the HiveQL query to retrieve customers with age greater than 30\n",
        "    retrieve_query = '''\n",
        "    SELECT *\n",
        "    FROM Customers\n",
        "    WHERE age > 30\n",
        "    '''\n",
        "    cursor.execute(retrieve_query)\n",
        "\n",
        "    # Fetch all the results\n",
        "    results = cursor.fetchall()\n",
        "\n",
        "    # Print the retrieved records\n",
        "    for row in results:\n",
        "        print(row)\n",
        "\n",
        "    # Close the connection\n",
        "    connection.close()\n",
        "\n",
        "# Call the function to retrieve customers with age greater than 30\n",
        "retrieve_customers_with_age_greater_than_30()"
      ],
      "metadata": {
        "id": "gc5ovTNWYloO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.  Write a Python script that sorts records in descending order based on the \"timestamp\" column in a Hive table named \"Logs.\"**"
      ],
      "metadata": {
        "id": "zYxrxcARZJmX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyhive import hive\n",
        "\n",
        "def sort_logs_by_timestamp_descending():\n",
        "    # Connect to Hive server\n",
        "    connection = hive.connect('localhost')\n",
        "\n",
        "    # Create a cursor\n",
        "    cursor = connection.cursor()\n",
        "\n",
        "    # Execute the HiveQL query to sort records by timestamp in descending order\n",
        "    sort_query = '''\n",
        "    SELECT *\n",
        "    FROM Logs\n",
        "    ORDER BY timestamp DESC\n",
        "    '''\n",
        "    cursor.execute(sort_query)\n",
        "\n",
        "    # Fetch all the results\n",
        "    results = cursor.fetchall()\n",
        "\n",
        "    # Print the sorted records\n",
        "    for row in results:\n",
        "        print(row)\n",
        "\n",
        "    # Close the connection\n",
        "    connection.close()\n",
        "\n",
        "# Call the function to sort logs by timestamp in descending order\n",
        "sort_logs_by_timestamp_descending()"
      ],
      "metadata": {
        "id": "XIMpRifnYlrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.  Write a Python program that connects to a Hive server using PyHive library and retrieves all records from a table named \"Products\".**"
      ],
      "metadata": {
        "id": "kS0WxRJ6ZUDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyhive import hive\n",
        "\n",
        "def retrieve_all_products():\n",
        "    # Connect to Hive server\n",
        "    connection = hive.connect('localhost')\n",
        "\n",
        "    # Create a cursor\n",
        "    cursor = connection.cursor()\n",
        "\n",
        "    # Execute the HiveQL query to retrieve all records from the \"Products\" table\n",
        "    retrieve_query = 'SELECT * FROM Products'\n",
        "    cursor.execute(retrieve_query)\n",
        "\n",
        "    # Fetch all the results\n",
        "    results = cursor.fetchall()\n",
        "\n",
        "    # Print the retrieved records\n",
        "    for row in results:\n",
        "        print(row)\n",
        "\n",
        "    # Close the connection\n",
        "    connection.close()\n",
        "\n",
        "# Call the function to retrieve all records from the \"Products\" table\n",
        "retrieve_all_products()"
      ],
      "metadata": {
        "id": "Ry6z8pn9Yltl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.  Write a Python script that calculates the average salary of employees from a Hive table named \"Employees\".**"
      ],
      "metadata": {
        "id": "2BNAFA4YZeA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyhive import hive\n",
        "\n",
        "def calculate_average_salary():\n",
        "    # Connect to Hive server\n",
        "    connection = hive.connect('localhost')\n",
        "\n",
        "    # Create a cursor\n",
        "    cursor = connection.cursor()\n",
        "\n",
        "    # Execute the HiveQL query to calculate the average salary\n",
        "    average_salary_query = 'SELECT AVG(salary) FROM Employees'\n",
        "    cursor.execute(average_salary_query)\n",
        "\n",
        "    # Fetch the result\n",
        "    result = cursor.fetchone()\n",
        "    average_salary = result[0]\n",
        "\n",
        "    # Print the average salary\n",
        "    print(f\"Average Salary: {average_salary}\")\n",
        "\n",
        "    # Close the connection\n",
        "    connection.close()\n",
        "\n",
        "# Call the function to calculate the average salary of employees\n",
        "calculate_average_salary()"
      ],
      "metadata": {
        "id": "dk-FrFdCYlwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.  Implement a Python program that uses Hive partitioning to create a partitioned table named \"Sales_Data\" based on the \"year\" and \"month\" columns.**"
      ],
      "metadata": {
        "id": "KffT2B_XZwnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyhive import hive\n",
        "\n",
        "def create_partitioned_table():\n",
        "    # Connect to Hive server\n",
        "    connection = hive.connect('localhost')\n",
        "\n",
        "    # Create a cursor\n",
        "    cursor = connection.cursor()\n",
        "\n",
        "    # Execute the HiveQL query to create the partitioned table\n",
        "    create_table_query = '''\n",
        "    CREATE TABLE Sales_Data (\n",
        "        -- Columns definition\n",
        "        column1 STRING,\n",
        "        column2 INT,\n",
        "        ...\n",
        "        year INT,\n",
        "        month INT\n",
        "    )\n",
        "    PARTITIONED BY (year INT, month INT)\n",
        "    '''\n",
        "    cursor.execute(create_table_query)\n",
        "\n",
        "    # Commit the changes and close the connection\n",
        "    connection.commit()\n",
        "    connection.close()\n",
        "\n",
        "    print(\"Partitioned table 'Sales_Data' created successfully!\")\n",
        "\n",
        "# Call the function to create the partitioned table\n",
        "create_partitioned_table()"
      ],
      "metadata": {
        "id": "jHL_NGrSYlyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7.  Develop a Python script that adds a new column named \"email\" of type string to an existing Hive table named \"Employees.\"**"
      ],
      "metadata": {
        "id": "L-7aP_K2Z8J-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyhive import hive\n",
        "\n",
        "def add_email_column():\n",
        "    # Connect to Hive server\n",
        "    connection = hive.connect('localhost')\n",
        "\n",
        "    # Create a cursor\n",
        "    cursor = connection.cursor()\n",
        "\n",
        "    # Execute the HiveQL query to add a new column named \"email\" to the \"Employees\" table\n",
        "    alter_table_query = 'ALTER TABLE Employees ADD COLUMNS (email STRING)'\n",
        "    cursor.execute(alter_table_query)\n",
        "\n",
        "    # Commit the changes and close the connection\n",
        "    connection.commit()\n",
        "    connection.close()\n",
        "\n",
        "    print(\"New column 'email' added to the 'Employees' table successfully!\")\n",
        "\n",
        "# Call the function to add the new column\n",
        "add_email_column()"
      ],
      "metadata": {
        "id": "yZ9E48INYl1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8.  Create a Python program that performs an inner join between two Hive tables, \"Orders\" and \"Customers,\" based on a common column.**"
      ],
      "metadata": {
        "id": "LXPMlc8oab49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyhive import hive\n",
        "\n",
        "def perform_inner_join():\n",
        "    # Connect to Hive server\n",
        "    connection = hive.connect('localhost')\n",
        "\n",
        "    # Create a cursor\n",
        "    cursor = connection.cursor()\n",
        "\n",
        "    # Execute the HiveQL query to perform the inner join\n",
        "    join_query = '''\n",
        "    SELECT *\n",
        "    FROM Orders\n",
        "    INNER JOIN Customers\n",
        "    ON Orders.customer_id = Customers.customer_id\n",
        "    '''\n",
        "    cursor.execute(join_query)\n",
        "\n",
        "    # Fetch all the results\n",
        "    results = cursor.fetchall()\n",
        "\n",
        "    # Print the joined records\n",
        "    for row in results:\n",
        "        print(row)\n",
        "\n",
        "    # Close the connection\n",
        "    connection.close()\n",
        "\n",
        "# Call the function to perform the inner join\n",
        "perform_inner_join()"
      ],
      "metadata": {
        "id": "GTv6FHONYl3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9.  Implement a Python program that uses the Hive SerDe library to process JSON data stored in a Hive table named \"User_Activity_Logs.**"
      ],
      "metadata": {
        "id": "OTVzuuy9aj3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyhive import hive\n",
        "\n",
        "def process_json_data():\n",
        "    # Connect to Hive server\n",
        "    connection = hive.connect('localhost')\n",
        "\n",
        "    # Create a cursor\n",
        "    cursor = connection.cursor()\n",
        "\n",
        "    # Execute the HiveQL query to select and process JSON data from the table\n",
        "    select_query = '''\n",
        "    SELECT *\n",
        "    FROM User_Activity_Logs\n",
        "    '''\n",
        "    cursor.execute(select_query)\n",
        "\n",
        "    # Fetch all the results\n",
        "    results = cursor.fetchall()\n",
        "\n",
        "    # Process the JSON data\n",
        "    for row in results:\n",
        "        json_data = row[0]  # Assuming the JSON data is stored in the first column\n",
        "        # Process the JSON data as needed\n",
        "        print(json_data)\n",
        "\n",
        "    # Close the connection\n",
        "    connection.close()\n",
        "\n",
        "# Call the function to process JSON data from the Hive table\n",
        "process_json_data()"
      ],
      "metadata": {
        "id": "gxoBrNZHYl6O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}